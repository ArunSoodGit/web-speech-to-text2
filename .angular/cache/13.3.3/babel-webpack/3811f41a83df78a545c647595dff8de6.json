{"ast":null,"code":"import { CancellationDetails, CancellationReason, ResultReason, SpeechConfig, SpeechRecognizer } from 'microsoft-cognitiveservices-speech-sdk';\nimport * as i0 from \"@angular/core\";\n\nclass SpeechRecognitionResultModel {}\n\nexport let AzureSpeechService = /*#__PURE__*/(() => {\n  class AzureSpeechService {\n    constructor() {\n      this.text2 = '';\n      this.text3 = '';\n    }\n\n    startContinuousRecognition(selectedLanguage) {\n      this.speechConfig = SpeechConfig.fromSubscription('e02cb196c708407ca4bfc365474b4afa', 'NorthEurope');\n      this.speechConfig.speechRecognitionLanguage = selectedLanguage;\n      this.speechConfig.enableDictation();\n      this.speechRecognizer = new SpeechRecognizer(this.speechConfig);\n\n      try {\n        this.speechRecognizer.startContinuousRecognitionAsync(() => {\n          console.log('Recognition started');\n\n          this.speechRecognizer.recognizing = (s, e) => {\n            console.log('recognizing text', e.result.text);\n            this.text2 = e.result.text;\n          };\n\n          this.asRecognitionStarted = true;\n        });\n\n        this.speechRecognizer.recognized = (s, e) => {\n          if (e.result.reason === ResultReason.RecognizedSpeech) {\n            console.log(`RECOGNIZED: Text=${e.result.text}`);\n            this.text3 = this.text3 + e.result.text; // const subs = generateSubtitles(e.result, settings)\n            // results.push(...subs)\n          } else if (e.result.reason === ResultReason.NoMatch) {\n            console.log('NOMATCH: Speech could not be recognized.');\n          } else {\n            console.log('SOMETHING DIFFERENT', e.result);\n          }\n        };\n      } catch (e) {\n        console.log('error', e);\n      }\n    }\n\n    stopRecognition() {\n      this.speechRecognizer.stopContinuousRecognitionAsync(() => {\n        this.speechRecognizer.close();\n      });\n    } //\n    // private handleRecognizingResponse(res: any): void  {\n    //   this.speechRecognitionResult.next({isFinal: false, result: res.result});\n    // }\n    //\n    // private handleRecognizedResponse(res: any): void {\n    //   this.speechRecognitionResult.next({isFinal: true, result: res.result});\n    // }\n    //\n    // private handleCanceled(res: any): void {\n    //   console.log('error', res);\n    // }\n\n\n    speechToText() {\n      return new Promise((resolve, reject) => {\n        this.speechRecognizer.recognizeOnceAsync(result => {\n          console.log(result.text);\n          let text = '';\n\n          switch (result.reason) {\n            case ResultReason.RecognizedSpeech:\n              text = result.text;\n              break;\n\n            case ResultReason.NoMatch:\n              text = 'Speech could not be recognized.';\n              reject(text);\n              break;\n\n            case ResultReason.Canceled:\n              const cancellation = CancellationDetails.fromResult(result);\n              text = 'Cancelled: Reason= ' + cancellation.reason;\n\n              if (cancellation.reason === CancellationReason.Error) {\n                text = 'Canceled: ' + cancellation.ErrorCode;\n              }\n\n              reject(text);\n              break;\n          }\n\n          resolve(text);\n        });\n      });\n    }\n\n  }\n\n  AzureSpeechService.ɵfac = function AzureSpeechService_Factory(t) {\n    return new (t || AzureSpeechService)();\n  };\n\n  AzureSpeechService.ɵprov = /*@__PURE__*/i0.ɵɵdefineInjectable({\n    token: AzureSpeechService,\n    factory: AzureSpeechService.ɵfac,\n    providedIn: 'root'\n  });\n  return AzureSpeechService;\n})();","map":null,"metadata":{},"sourceType":"module"}