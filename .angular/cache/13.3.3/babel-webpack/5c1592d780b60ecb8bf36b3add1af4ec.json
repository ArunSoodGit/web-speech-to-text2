{"ast":null,"code":"// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nimport { connectivity, type } from \"../common.speech/Exports\";\nimport { AudioSourceErrorEvent, AudioSourceInitializingEvent, AudioSourceOffEvent, AudioSourceReadyEvent, AudioStreamNodeAttachedEvent, AudioStreamNodeAttachingEvent, AudioStreamNodeDetachedEvent, AudioStreamNodeErrorEvent, ChunkedArrayBufferStream, createNoDashGuid, Deferred, Events, EventSource } from \"../common/Exports\";\nimport { AudioStreamFormat, AudioStreamFormatImpl } from \"../sdk/Audio/AudioStreamFormat\";\nexport const AudioWorkletSourceURLPropertyName = \"MICROPHONE-WorkletSourceUrl\";\nexport class MicAudioSource {\n  constructor(privRecorder, deviceId, audioSourceId, mediaStream) {\n    this.privRecorder = privRecorder;\n    this.deviceId = deviceId;\n    this.privStreams = {};\n    this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;\n    this.privId = audioSourceId ? audioSourceId : createNoDashGuid();\n    this.privEvents = new EventSource();\n    this.privMediaStream = mediaStream || null;\n    this.privIsClosing = false;\n  }\n\n  get format() {\n    return Promise.resolve(MicAudioSource.AUDIOFORMAT);\n  }\n\n  get blob() {\n    return Promise.reject(\"Not implemented for Mic input\");\n  }\n\n  turnOn() {\n    if (this.privInitializeDeferral) {\n      return this.privInitializeDeferral.promise;\n    }\n\n    this.privInitializeDeferral = new Deferred();\n\n    try {\n      this.createAudioContext();\n    } catch (error) {\n      if (error instanceof Error) {\n        const typedError = error;\n        this.privInitializeDeferral.reject(typedError.name + \": \" + typedError.message);\n      } else {\n        this.privInitializeDeferral.reject(error);\n      }\n\n      return this.privInitializeDeferral.promise;\n    }\n\n    const nav = window.navigator;\n    let getUserMedia = // eslint-disable-next-line\n    nav.getUserMedia || nav.webkitGetUserMedia || nav.mozGetUserMedia || nav.msGetUserMedia;\n\n    if (!!nav.mediaDevices) {\n      getUserMedia = (constraints, successCallback, errorCallback) => {\n        nav.mediaDevices.getUserMedia(constraints).then(successCallback).catch(errorCallback);\n      };\n    }\n\n    if (!getUserMedia) {\n      const errorMsg = \"Browser does not support getUserMedia.\";\n      this.privInitializeDeferral.reject(errorMsg);\n      this.onEvent(new AudioSourceErrorEvent(errorMsg, \"\")); // mic initialized error - no streamid at this point\n    } else {\n      const next = () => {\n        this.onEvent(new AudioSourceInitializingEvent(this.privId)); // no stream id\n\n        if (this.privMediaStream && this.privMediaStream.active) {\n          this.onEvent(new AudioSourceReadyEvent(this.privId));\n          this.privInitializeDeferral.resolve();\n        } else {\n          getUserMedia({\n            audio: this.deviceId ? {\n              deviceId: this.deviceId\n            } : true,\n            video: false\n          }, mediaStream => {\n            this.privMediaStream = mediaStream;\n            this.onEvent(new AudioSourceReadyEvent(this.privId));\n            this.privInitializeDeferral.resolve();\n          }, error => {\n            const errorMsg = `Error occurred during microphone initialization: ${error}`;\n            this.privInitializeDeferral.reject(errorMsg);\n            this.onEvent(new AudioSourceErrorEvent(this.privId, errorMsg));\n          });\n        }\n      };\n\n      if (this.privContext.state === \"suspended\") {\n        // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.\n        // https://github.com/WebAudio/web-audio-api/issues/790\n        this.privContext.resume().then(next).catch(reason => {\n          this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);\n        });\n      } else {\n        next();\n      }\n    }\n\n    return this.privInitializeDeferral.promise;\n  }\n\n  id() {\n    return this.privId;\n  }\n\n  attach(audioNodeId) {\n    this.onEvent(new AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n    return this.listen(audioNodeId).then(stream => {\n      this.onEvent(new AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n      return {\n        detach: () => __awaiter(this, void 0, void 0, function* () {\n          stream.readEnded();\n          delete this.privStreams[audioNodeId];\n          this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n          return this.turnOff();\n        }),\n        id: () => audioNodeId,\n        read: () => stream.read()\n      };\n    });\n  }\n\n  detach(audioNodeId) {\n    if (audioNodeId && this.privStreams[audioNodeId]) {\n      this.privStreams[audioNodeId].close();\n      delete this.privStreams[audioNodeId];\n      this.onEvent(new AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n  }\n\n  turnOff() {\n    return __awaiter(this, void 0, void 0, function* () {\n      for (const streamId in this.privStreams) {\n        if (streamId) {\n          const stream = this.privStreams[streamId];\n\n          if (stream) {\n            stream.close();\n          }\n        }\n      }\n\n      this.onEvent(new AudioSourceOffEvent(this.privId)); // no stream now\n\n      if (this.privInitializeDeferral) {\n        // Correctly handle when browser forces mic off before turnOn() completes\n        // eslint-disable-next-line @typescript-eslint/await-thenable\n        yield this.privInitializeDeferral;\n        this.privInitializeDeferral = null;\n      }\n\n      yield this.destroyAudioContext();\n      return;\n    });\n  }\n\n  get events() {\n    return this.privEvents;\n  }\n\n  get deviceInfo() {\n    return this.getMicrophoneLabel().then(label => ({\n      bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,\n      channelcount: MicAudioSource.AUDIOFORMAT.channels,\n      connectivity: connectivity.Unknown,\n      manufacturer: \"Speech SDK\",\n      model: label,\n      samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,\n      type: type.Microphones\n    }));\n  }\n\n  setProperty(name, value) {\n    if (name === AudioWorkletSourceURLPropertyName) {\n      this.privRecorder.setWorkletUrl(value);\n    } else {\n      throw new Error(\"Property '\" + name + \"' is not supported on Microphone.\");\n    }\n  }\n\n  getMicrophoneLabel() {\n    const defaultMicrophoneName = \"microphone\"; // If we did this already, return the value.\n\n    if (this.privMicrophoneLabel !== undefined) {\n      return Promise.resolve(this.privMicrophoneLabel);\n    } // If the stream isn't currently running, we can't query devices because security.\n\n\n    if (this.privMediaStream === undefined || !this.privMediaStream.active) {\n      return Promise.resolve(defaultMicrophoneName);\n    } // Setup a default\n\n\n    this.privMicrophoneLabel = defaultMicrophoneName; // Get the id of the device running the audio track.\n\n    const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId; // If the browser doesn't support getting the device ID, set a default and return.\n\n    if (undefined === microphoneDeviceId) {\n      return Promise.resolve(this.privMicrophoneLabel);\n    }\n\n    const deferred = new Deferred(); // Enumerate the media devices.\n\n    navigator.mediaDevices.enumerateDevices().then(devices => {\n      for (const device of devices) {\n        if (device.deviceId === microphoneDeviceId) {\n          // Found the device\n          this.privMicrophoneLabel = device.label;\n          break;\n        }\n      }\n\n      deferred.resolve(this.privMicrophoneLabel);\n    }, () => deferred.resolve(this.privMicrophoneLabel));\n    return deferred.promise;\n  }\n\n  listen(audioNodeId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.turnOn();\n      const stream = new ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);\n      this.privStreams[audioNodeId] = stream;\n\n      try {\n        this.privRecorder.record(this.privContext, this.privMediaStream, stream);\n      } catch (error) {\n        this.onEvent(new AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));\n        throw error;\n      }\n\n      const result = stream;\n      return result;\n    });\n  }\n\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    Events.instance.onEvent(event);\n  }\n\n  createAudioContext() {\n    if (!!this.privContext) {\n      return;\n    }\n\n    this.privContext = AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);\n  }\n\n  destroyAudioContext() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privContext) {\n        return;\n      }\n\n      this.privRecorder.releaseMediaResources(this.privContext); // This pattern brought to you by a bug in the TypeScript compiler where it\n      // confuses the (\"close\" in this.privContext) with this.privContext always being null as the alternate.\n      // https://github.com/Microsoft/TypeScript/issues/11498\n\n      let hasClose = false;\n\n      if (\"close\" in this.privContext) {\n        hasClose = true;\n      }\n\n      if (hasClose) {\n        if (!this.privIsClosing) {\n          // The audio context close may take enough time that the close is called twice\n          this.privIsClosing = true;\n          yield this.privContext.close();\n          this.privContext = null;\n          this.privIsClosing = false;\n        }\n      } else if (null !== this.privContext && this.privContext.state === \"running\") {\n        // Suspend actually takes a callback, but analogous to the\n        // resume method, it'll be only fired if suspend is called\n        // in a direct response to a user action. The later is not always\n        // the case, as TurnOff is also called, when we receive an\n        // end-of-speech message from the service. So, doing a best effort\n        // fire-and-forget here.\n        yield this.privContext.suspend();\n      }\n    });\n  }\n\n}\nMicAudioSource.AUDIOFORMAT = AudioStreamFormat.getDefaultInputFormat(); //# sourceMappingURL=MicAudioSource.js.map","map":null,"metadata":{},"sourceType":"module"}