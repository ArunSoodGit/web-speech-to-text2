{"ast":null,"code":"// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nimport { createNoDashGuid, Deferred, Events } from \"../common/Exports\";\nimport { PullAudioOutputStreamImpl } from \"../sdk/Audio/AudioOutputStream\";\nimport { MetadataType } from \"./ServiceMessages/SynthesisAudioMetadata\";\nimport { SynthesisAdapterBase } from \"./SynthesisAdapterBase\";\nimport { ConnectingToSynthesisServiceEvent, SynthesisStartedEvent, SynthesisTriggeredEvent } from \"./SynthesisEvents\";\nexport class SynthesisTurn {\n  constructor() {\n    this.privIsDisposed = false;\n    this.privIsSynthesizing = false;\n    this.privIsSynthesisEnded = false;\n    this.privBytesReceived = 0;\n    this.privInTurn = false;\n    this.privTextOffset = 0;\n    this.privNextSearchTextIndex = 0;\n    this.privSentenceOffset = 0;\n    this.privNextSearchSentenceIndex = 0;\n    this.privRequestId = createNoDashGuid();\n    this.privTurnDeferral = new Deferred(); // We're not in a turn, so resolve.\n\n    this.privTurnDeferral.resolve();\n  }\n\n  get requestId() {\n    return this.privRequestId;\n  }\n\n  get streamId() {\n    return this.privStreamId;\n  }\n\n  set streamId(value) {\n    this.privStreamId = value;\n  }\n\n  get audioOutputFormat() {\n    return this.privAudioOutputFormat;\n  }\n\n  set audioOutputFormat(format) {\n    this.privAudioOutputFormat = format;\n  }\n\n  get turnCompletionPromise() {\n    return this.privTurnDeferral.promise;\n  }\n\n  get isSynthesisEnded() {\n    return this.privIsSynthesisEnded;\n  }\n\n  get isSynthesizing() {\n    return this.privIsSynthesizing;\n  }\n\n  get currentTextOffset() {\n    return this.privTextOffset;\n  }\n\n  get currentSentenceOffset() {\n    return this.privSentenceOffset;\n  } // The number of bytes received for current turn\n\n\n  get bytesReceived() {\n    return this.privBytesReceived;\n  }\n\n  get audioDuration() {\n    return this.privAudioDuration;\n  }\n\n  getAllReceivedAudio() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privReceivedAudio) {\n        return Promise.resolve(this.privReceivedAudio);\n      }\n\n      if (!this.privIsSynthesisEnded) {\n        return null;\n      }\n\n      yield this.readAllAudioFromStream();\n      return Promise.resolve(this.privReceivedAudio);\n    });\n  }\n\n  getAllReceivedAudioWithHeader() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privReceivedAudioWithHeader) {\n        return this.privReceivedAudioWithHeader;\n      }\n\n      if (!this.privIsSynthesisEnded) {\n        return null;\n      }\n\n      if (this.audioOutputFormat.hasHeader) {\n        const audio = yield this.getAllReceivedAudio();\n        this.privReceivedAudioWithHeader = SynthesisAdapterBase.addHeader(audio, this.audioOutputFormat);\n        return this.privReceivedAudioWithHeader;\n      } else {\n        return this.getAllReceivedAudio();\n      }\n    });\n  }\n\n  startNewSynthesis(requestId, rawText, isSSML, audioDestination) {\n    this.privIsSynthesisEnded = false;\n    this.privIsSynthesizing = true;\n    this.privRequestId = requestId;\n    this.privRawText = rawText;\n    this.privIsSSML = isSSML;\n    this.privAudioOutputStream = new PullAudioOutputStreamImpl();\n    this.privAudioOutputStream.format = this.privAudioOutputFormat;\n    this.privReceivedAudio = null;\n    this.privReceivedAudioWithHeader = null;\n    this.privBytesReceived = 0;\n    this.privTextOffset = 0;\n    this.privNextSearchTextIndex = 0;\n    this.privSentenceOffset = 0;\n    this.privNextSearchSentenceIndex = 0;\n    this.privPartialVisemeAnimation = \"\";\n\n    if (audioDestination !== undefined) {\n      this.privTurnAudioDestination = audioDestination;\n      this.privTurnAudioDestination.format = this.privAudioOutputFormat;\n    }\n\n    this.onEvent(new SynthesisTriggeredEvent(this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));\n  }\n\n  onPreConnectionStart(authFetchEventId) {\n    this.privAuthFetchEventId = authFetchEventId;\n    this.onEvent(new ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));\n  }\n\n  onAuthCompleted(isError) {\n    if (isError) {\n      this.onComplete();\n    }\n  }\n\n  onConnectionEstablishCompleted(statusCode) {\n    if (statusCode === 200) {\n      this.onEvent(new SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));\n      this.privBytesReceived = 0;\n      return;\n    } else if (statusCode === 403) {\n      this.onComplete();\n    }\n  }\n\n  onServiceResponseMessage(responseJson) {\n    const response = JSON.parse(responseJson);\n    this.streamId = response.audio.streamId;\n  }\n\n  onServiceTurnEndResponse() {\n    this.privInTurn = false;\n    this.privTurnDeferral.resolve();\n    this.onComplete();\n  }\n\n  onServiceTurnStartResponse() {\n    if (!!this.privTurnDeferral && !!this.privInTurn) {\n      // What? How are we starting a turn with another not done?\n      this.privTurnDeferral.reject(\"Another turn started before current completed.\"); // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n      // eslint-disable-next-line @typescript-eslint/no-empty-function\n\n      this.privTurnDeferral.promise.then().catch(() => {});\n    }\n\n    this.privInTurn = true;\n    this.privTurnDeferral = new Deferred();\n  }\n\n  onAudioChunkReceived(data) {\n    if (this.isSynthesizing) {\n      this.privAudioOutputStream.write(data);\n      this.privBytesReceived += data.byteLength;\n\n      if (this.privTurnAudioDestination !== undefined) {\n        this.privTurnAudioDestination.write(data);\n      }\n    }\n  }\n\n  onTextBoundaryEvent(metadata) {\n    this.updateTextOffset(metadata.Data.text.Text, metadata.Type);\n  }\n\n  onVisemeMetadataReceived(metadata) {\n    if (metadata.Data.AnimationChunk !== undefined) {\n      this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;\n    }\n  }\n\n  onSessionEnd(metadata) {\n    this.privAudioDuration = metadata.Data.Offset;\n  }\n\n  dispose() {\n    if (!this.privIsDisposed) {\n      // we should have completed by now. If we did not its an unknown error.\n      this.privIsDisposed = true;\n    }\n  }\n\n  onStopSynthesizing() {\n    this.onComplete();\n  }\n  /**\n   * Gets the viseme animation string (merged from animation chunk), and clears the internal\n   * partial animation.\n   */\n\n\n  getAndClearVisemeAnimation() {\n    const animation = this.privPartialVisemeAnimation;\n    this.privPartialVisemeAnimation = \"\";\n    return animation;\n  }\n\n  onEvent(event) {\n    Events.instance.onEvent(event);\n  }\n  /**\n   * Check if the text is an XML(SSML) tag\n   * @param text\n   * @private\n   */\n\n\n  static isXmlTag(text) {\n    return text.length >= 2 && text[0] === \"<\" && text[text.length - 1] === \">\";\n  }\n\n  updateTextOffset(text, type) {\n    if (type === MetadataType.WordBoundary) {\n      this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);\n\n      if (this.privTextOffset >= 0) {\n        this.privNextSearchTextIndex = this.privTextOffset + text.length;\n\n        if (this.privIsSSML) {\n          if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {\n            this.updateTextOffset(text, type);\n          }\n        }\n      }\n    } else {\n      this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);\n\n      if (this.privSentenceOffset >= 0) {\n        this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;\n\n        if (this.privIsSSML) {\n          if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {\n            this.updateTextOffset(text, type);\n          }\n        }\n      }\n    }\n  }\n\n  onComplete() {\n    if (this.privIsSynthesizing) {\n      this.privIsSynthesizing = false;\n      this.privIsSynthesisEnded = true;\n      this.privAudioOutputStream.close();\n      this.privInTurn = false;\n\n      if (this.privTurnAudioDestination !== undefined) {\n        this.privTurnAudioDestination.close();\n        this.privTurnAudioDestination = undefined;\n      }\n    }\n  }\n\n  readAllAudioFromStream() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privIsSynthesisEnded) {\n        this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);\n\n        try {\n          yield this.privAudioOutputStream.read(this.privReceivedAudio);\n        } catch (e) {\n          this.privReceivedAudio = new ArrayBuffer(0);\n        }\n      }\n    });\n  }\n  /**\n   * Check if current idx is in XML(SSML) tag\n   * @param idx\n   * @private\n   */\n\n\n  withinXmlTag(idx) {\n    return this.privRawText.indexOf(\"<\", idx + 1) > this.privRawText.indexOf(\">\", idx + 1);\n  }\n\n} //# sourceMappingURL=SynthesisTurn.js.map","map":null,"metadata":{},"sourceType":"module"}