{"ast":null,"code":"/* eslint-disable @typescript-eslint/no-empty-function */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nimport { AutoDetectSourceLanguagesOpenRangeOptionName, CognitiveSubscriptionKeyAuthentication, CognitiveTokenAuthentication, Context, OS, SpeechServiceConfig, SpeechSynthesisConnectionFactory, SynthesisAdapterBase, SynthesisRestAdapter, SynthesizerConfig } from \"../common.speech/Exports\";\nimport { createNoDashGuid, marshalPromiseToCallbacks, Queue } from \"../common/Exports\";\nimport { AudioFileWriter } from \"./Audio/AudioFileWriter\";\nimport { AudioOutputFormatImpl } from \"./Audio/AudioOutputFormat\";\nimport { PushAudioOutputStreamImpl } from \"./Audio/AudioOutputStream\";\nimport { Contracts } from \"./Contracts\";\nimport { AudioConfig, PropertyId, PullAudioOutputStream, PushAudioOutputStreamCallback, SpeechSynthesisOutputFormat, SynthesisVoicesResult } from \"./Exports\";\n/**\n * Defines the class SpeechSynthesizer for text to speech.\n * Updated in version 1.16.0\n * @class SpeechSynthesizer\n */\n\nexport class SpeechSynthesizer {\n  /**\n   * SpeechSynthesizer constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.\n   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.\n   */\n  constructor(speechConfig, audioConfig) {\n    const speechConfigImpl = speechConfig;\n    Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n\n    if (audioConfig !== null) {\n      if (audioConfig === undefined) {\n        this.audioConfig = typeof window === \"undefined\" ? undefined : AudioConfig.fromDefaultSpeakerOutput();\n      } else {\n        this.audioConfig = audioConfig;\n      }\n    }\n\n    this.privProperties = speechConfigImpl.properties.clone();\n    this.privDisposed = false;\n    this.privSynthesizing = false;\n    this.privConnectionFactory = new SpeechSynthesisConnectionFactory();\n    this.synthesisRequestQueue = new Queue();\n    this.implCommonSynthesizeSetup();\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member SpeechSynthesizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n\n\n  get authorizationToken() {\n    return this.properties.getProperty(PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * @member SpeechSynthesizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} token - Authorization token.\n   */\n\n\n  set authorizationToken(token) {\n    Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  /**\n   * The collection of properties and their values defined for this SpeechSynthesizer.\n   * @member SpeechSynthesizer.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.\n   */\n\n\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Indicates if auto detect source language is enabled\n   * @member SpeechSynthesizer.prototype.properties\n   * @function\n   * @public\n   * @returns {boolean} if auto detect source language is enabled\n   */\n\n\n  get autoDetectSourceLanguage() {\n    return this.properties.getProperty(PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages) === AutoDetectSourceLanguagesOpenRangeOptionName;\n  }\n  /**\n   * SpeechSynthesizer constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer\n   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer\n   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer\n   */\n\n\n  static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n    const speechConfigImpl = speechConfig;\n    autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n    return new SpeechSynthesizer(speechConfig, audioConfig);\n  }\n\n  buildSsml(text) {\n    const languageToDefaultVoice = {\n      [\"af-ZA\"]: \"af-ZA-AdriNeural\",\n      [\"am-ET\"]: \"am-ET-AmehaNeural\",\n      [\"ar-AE\"]: \"ar-AE-FatimaNeural\",\n      [\"ar-BH\"]: \"ar-BH-AliNeural\",\n      [\"ar-DZ\"]: \"ar-DZ-AminaNeural\",\n      [\"ar-EG\"]: \"ar-EG-SalmaNeural\",\n      [\"ar-IQ\"]: \"ar-IQ-BasselNeural\",\n      [\"ar-JO\"]: \"ar-JO-SanaNeural\",\n      [\"ar-KW\"]: \"ar-KW-FahedNeural\",\n      [\"ar-LY\"]: \"ar-LY-ImanNeural\",\n      [\"ar-MA\"]: \"ar-MA-JamalNeural\",\n      [\"ar-QA\"]: \"ar-QA-AmalNeural\",\n      [\"ar-SA\"]: \"ar-SA-HamedNeural\",\n      [\"ar-SY\"]: \"ar-SY-AmanyNeural\",\n      [\"ar-TN\"]: \"ar-TN-HediNeural\",\n      [\"ar-YE\"]: \"ar-YE-MaryamNeural\",\n      [\"bg-BG\"]: \"bg-BG-BorislavNeural\",\n      [\"bn-BD\"]: \"bn-BD-NabanitaNeural\",\n      [\"bn-IN\"]: \"bn-IN-BashkarNeural\",\n      [\"ca-ES\"]: \"ca-ES-JoanaNeural\",\n      [\"cs-CZ\"]: \"cs-CZ-AntoninNeural\",\n      [\"cy-GB\"]: \"cy-GB-AledNeural\",\n      [\"da-DK\"]: \"da-DK-ChristelNeural\",\n      [\"de-AT\"]: \"de-AT-IngridNeural\",\n      [\"de-CH\"]: \"de-CH-JanNeural\",\n      [\"de-DE\"]: \"de-DE-KatjaNeural\",\n      [\"el-GR\"]: \"el-GR-AthinaNeural\",\n      [\"en-AU\"]: \"en-AU-NatashaNeural\",\n      [\"en-CA\"]: \"en-CA-ClaraNeural\",\n      [\"en-GB\"]: \"en-GB-LibbyNeural\",\n      [\"en-HK\"]: \"en-HK-SamNeural\",\n      [\"en-IE\"]: \"en-IE-ConnorNeural\",\n      [\"en-IN\"]: \"en-IN-NeerjaNeural\",\n      [\"en-KE\"]: \"en-KE-AsiliaNeural\",\n      [\"en-NG\"]: \"en-NG-AbeoNeural\",\n      [\"en-NZ\"]: \"en-NZ-MitchellNeural\",\n      [\"en-PH\"]: \"en-PH-JamesNeural\",\n      [\"en-SG\"]: \"en-SG-LunaNeural\",\n      [\"en-TZ\"]: \"en-TZ-ElimuNeural\",\n      [\"en-US\"]: \"en-US-JennyNeural\",\n      [\"en-ZA\"]: \"en-ZA-LeahNeural\",\n      [\"es-AR\"]: \"es-AR-ElenaNeural\",\n      [\"es-BO\"]: \"es-BO-MarceloNeural\",\n      [\"es-CL\"]: \"es-CL-CatalinaNeural\",\n      [\"es-CO\"]: \"es-CO-GonzaloNeural\",\n      [\"es-CR\"]: \"es-CR-JuanNeural\",\n      [\"es-CU\"]: \"es-CU-BelkysNeural\",\n      [\"es-DO\"]: \"es-DO-EmilioNeural\",\n      [\"es-EC\"]: \"es-EC-AndreaNeural\",\n      [\"es-ES\"]: \"es-ES-AlvaroNeural\",\n      [\"es-GQ\"]: \"es-GQ-JavierNeural\",\n      [\"es-GT\"]: \"es-GT-AndresNeural\",\n      [\"es-HN\"]: \"es-HN-CarlosNeural\",\n      [\"es-MX\"]: \"es-MX-DaliaNeural\",\n      [\"es-NI\"]: \"es-NI-FedericoNeural\",\n      [\"es-PA\"]: \"es-PA-MargaritaNeural\",\n      [\"es-PE\"]: \"es-PE-AlexNeural\",\n      [\"es-PR\"]: \"es-PR-KarinaNeural\",\n      [\"es-PY\"]: \"es-PY-MarioNeural\",\n      [\"es-SV\"]: \"es-SV-LorenaNeural\",\n      [\"es-US\"]: \"es-US-AlonsoNeural\",\n      [\"es-UY\"]: \"es-UY-MateoNeural\",\n      [\"es-VE\"]: \"es-VE-PaolaNeural\",\n      [\"et-EE\"]: \"et-EE-AnuNeural\",\n      [\"fa-IR\"]: \"fa-IR-DilaraNeural\",\n      [\"fi-FI\"]: \"fi-FI-SelmaNeural\",\n      [\"fil-PH\"]: \"fil-PH-AngeloNeural\",\n      [\"fr-BE\"]: \"fr-BE-CharlineNeural\",\n      [\"fr-CA\"]: \"fr-CA-SylvieNeural\",\n      [\"fr-CH\"]: \"fr-CH-ArianeNeural\",\n      [\"fr-FR\"]: \"fr-FR-DeniseNeural\",\n      [\"ga-IE\"]: \"ga-IE-ColmNeural\",\n      [\"gl-ES\"]: \"gl-ES-RoiNeural\",\n      [\"gu-IN\"]: \"gu-IN-DhwaniNeural\",\n      [\"he-IL\"]: \"he-IL-AvriNeural\",\n      [\"hi-IN\"]: \"hi-IN-MadhurNeural\",\n      [\"hr-HR\"]: \"hr-HR-GabrijelaNeural\",\n      [\"hu-HU\"]: \"hu-HU-NoemiNeural\",\n      [\"id-ID\"]: \"id-ID-ArdiNeural\",\n      [\"is-IS\"]: \"is-IS-GudrunNeural\",\n      [\"it-IT\"]: \"it-IT-IsabellaNeural\",\n      [\"ja-JP\"]: \"ja-JP-NanamiNeural\",\n      [\"jv-ID\"]: \"jv-ID-DimasNeural\",\n      [\"kk-KZ\"]: \"kk-KZ-AigulNeural\",\n      [\"km-KH\"]: \"km-KH-PisethNeural\",\n      [\"kn-IN\"]: \"kn-IN-GaganNeural\",\n      [\"ko-KR\"]: \"ko-KR-SunHiNeural\",\n      [\"lo-LA\"]: \"lo-LA-ChanthavongNeural\",\n      [\"lt-LT\"]: \"lt-LT-LeonasNeural\",\n      [\"lv-LV\"]: \"lv-LV-EveritaNeural\",\n      [\"mk-MK\"]: \"mk-MK-AleksandarNeural\",\n      [\"ml-IN\"]: \"ml-IN-MidhunNeural\",\n      [\"mr-IN\"]: \"mr-IN-AarohiNeural\",\n      [\"ms-MY\"]: \"ms-MY-OsmanNeural\",\n      [\"mt-MT\"]: \"mt-MT-GraceNeural\",\n      [\"my-MM\"]: \"my-MM-NilarNeural\",\n      [\"nb-NO\"]: \"nb-NO-PernilleNeural\",\n      [\"nl-BE\"]: \"nl-BE-ArnaudNeural\",\n      [\"nl-NL\"]: \"nl-NL-ColetteNeural\",\n      [\"pl-PL\"]: \"pl-PL-AgnieszkaNeural\",\n      [\"ps-AF\"]: \"ps-AF-GulNawazNeural\",\n      [\"pt-BR\"]: \"pt-BR-FranciscaNeural\",\n      [\"pt-PT\"]: \"pt-PT-DuarteNeural\",\n      [\"ro-RO\"]: \"ro-RO-AlinaNeural\",\n      [\"ru-RU\"]: \"ru-RU-SvetlanaNeural\",\n      [\"si-LK\"]: \"si-LK-SameeraNeural\",\n      [\"sk-SK\"]: \"sk-SK-LukasNeural\",\n      [\"sl-SI\"]: \"sl-SI-PetraNeural\",\n      [\"so-SO\"]: \"so-SO-MuuseNeural\",\n      [\"sr-RS\"]: \"sr-RS-NicholasNeural\",\n      [\"su-ID\"]: \"su-ID-JajangNeural\",\n      [\"sv-SE\"]: \"sv-SE-SofieNeural\",\n      [\"sw-KE\"]: \"sw-KE-RafikiNeural\",\n      [\"sw-TZ\"]: \"sw-TZ-DaudiNeural\",\n      [\"ta-IN\"]: \"ta-IN-PallaviNeural\",\n      [\"ta-LK\"]: \"ta-LK-KumarNeural\",\n      [\"ta-SG\"]: \"ta-SG-AnbuNeural\",\n      [\"te-IN\"]: \"te-IN-MohanNeural\",\n      [\"th-TH\"]: \"th-TH-PremwadeeNeural\",\n      [\"tr-TR\"]: \"tr-TR-AhmetNeural\",\n      [\"uk-UA\"]: \"uk-UA-OstapNeural\",\n      [\"ur-IN\"]: \"ur-IN-GulNeural\",\n      [\"ur-PK\"]: \"ur-PK-AsadNeural\",\n      [\"uz-UZ\"]: \"uz-UZ-MadinaNeural\",\n      [\"vi-VN\"]: \"vi-VN-HoaiMyNeural\",\n      [\"zh-CN\"]: \"zh-CN-XiaoxiaoNeural\",\n      [\"zh-HK\"]: \"zh-HK-HiuMaanNeural\",\n      [\"zh-TW\"]: \"zh-TW-HsiaoChenNeural\",\n      [\"zu-ZA\"]: \"zu-ZA-ThandoNeural\"\n    };\n    let language = this.properties.getProperty(PropertyId.SpeechServiceConnection_SynthLanguage, \"en-US\");\n    let voice = this.properties.getProperty(PropertyId.SpeechServiceConnection_SynthVoice, \"\");\n    let ssml = SpeechSynthesizer.XMLEncode(text);\n\n    if (this.autoDetectSourceLanguage) {\n      language = \"en-US\";\n    } else {\n      voice = voice || languageToDefaultVoice[language];\n    }\n\n    if (voice) {\n      ssml = `<voice name='${voice}'>${ssml}</voice>`;\n    }\n\n    ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;\n    return ssml;\n  }\n  /**\n   * Executes speech synthesis on plain text.\n   * The task returns the synthesis result.\n   * @member SpeechSynthesizer.prototype.speakTextAsync\n   * @function\n   * @public\n   * @param text - Text to be synthesized.\n   * @param cb - Callback that received the SpeechSynthesisResult.\n   * @param err - Callback invoked in case of an error.\n   * @param stream - AudioOutputStream to receive the synthesized audio.\n   */\n\n\n  speakTextAsync(text, cb, err, stream) {\n    this.speakImpl(text, false, cb, err, stream);\n  }\n  /**\n   * Executes speech synthesis on SSML.\n   * The task returns the synthesis result.\n   * @member SpeechSynthesizer.prototype.speakSsmlAsync\n   * @function\n   * @public\n   * @param ssml - SSML to be synthesized.\n   * @param cb - Callback that received the SpeechSynthesisResult.\n   * @param err - Callback invoked in case of an error.\n   * @param stream - AudioOutputStream to receive the synthesized audio.\n   */\n\n\n  speakSsmlAsync(ssml, cb, err, stream) {\n    this.speakImpl(ssml, true, cb, err, stream);\n  }\n  /**\n   * Get list of synthesis voices available.\n   * The task returns the synthesis voice result.\n   * @member SpeechSynthesizer.prototype.getVoicesAsync\n   * @function\n   * @async\n   * @public\n   * @param locale - Locale of voices in BCP-47 format; if left empty, get all available voices.\n   * @return {Promise<SynthesisVoicesResult>} - Promise of a SynthesisVoicesResult.\n   */\n\n\n  getVoicesAsync(locale = \"\") {\n    return __awaiter(this, void 0, void 0, function* () {\n      return this.getVoices(locale);\n    });\n  }\n  /**\n   * Dispose of associated resources.\n   * @member SpeechSynthesizer.prototype.close\n   * @function\n   * @public\n   */\n\n\n  close(cb, err) {\n    Contracts.throwIfDisposed(this.privDisposed);\n    marshalPromiseToCallbacks(this.dispose(true), cb, err);\n  }\n  /**\n   * @Internal\n   * Do not use externally, object returned will change without warning or notice.\n   */\n\n\n  get internalData() {\n    return this.privAdapter;\n  }\n  /**\n   * This method performs cleanup of resources.\n   * The Boolean parameter disposing indicates whether the method is called\n   * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n   * Derived classes should override this method to dispose resource if needed.\n   * @member SpeechSynthesizer.prototype.dispose\n   * @function\n   * @public\n   * @param {boolean} disposing - Flag to request disposal.\n   */\n\n\n  dispose(disposing) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposed) {\n        return;\n      }\n\n      if (disposing) {\n        if (this.privAdapter) {\n          yield this.privAdapter.dispose();\n        }\n      }\n\n      this.privDisposed = true;\n    });\n  } //\n  // ################################################################################################################\n  // IMPLEMENTATION.\n  // Move to independent class\n  // ################################################################################################################\n  //\n\n\n  createSynthesizerConfig(speechConfig) {\n    return new SynthesizerConfig(speechConfig, this.privProperties);\n  } // Creates the synthesis adapter\n\n\n  createSynthesisAdapter(authentication, connectionFactory, audioConfig, synthesizerConfig) {\n    return new SynthesisAdapterBase(authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);\n  }\n\n  implCommonSynthesizeSetup() {\n    let osPlatform = typeof window !== \"undefined\" ? \"Browser\" : \"Node\";\n    let osName = \"unknown\";\n    let osVersion = \"unknown\";\n\n    if (typeof navigator !== \"undefined\") {\n      osPlatform = osPlatform + \"/\" + navigator.platform;\n      osName = navigator.userAgent;\n      osVersion = navigator.appVersion;\n    }\n\n    const synthesizerConfig = this.createSynthesizerConfig(new SpeechServiceConfig(new Context(new OS(osPlatform, osName, osVersion))));\n    const subscriptionKey = this.privProperties.getProperty(PropertyId.SpeechServiceConnection_Key, undefined);\n    const authentication = subscriptionKey && subscriptionKey !== \"\" ? new CognitiveSubscriptionKeyAuthentication(subscriptionKey) : new CognitiveTokenAuthentication(() => {\n      const authorizationToken = this.privProperties.getProperty(PropertyId.SpeechServiceAuthorization_Token, undefined);\n      return Promise.resolve(authorizationToken);\n    }, () => {\n      const authorizationToken = this.privProperties.getProperty(PropertyId.SpeechServiceAuthorization_Token, undefined);\n      return Promise.resolve(authorizationToken);\n    });\n    this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, this.audioConfig, synthesizerConfig);\n    this.privAdapter.audioOutputFormat = AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(SpeechSynthesisOutputFormat[this.properties.getProperty(PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)]);\n    this.privRestAdapter = new SynthesisRestAdapter(synthesizerConfig);\n  }\n\n  speakImpl(text, IsSsml, cb, err, dataStream) {\n    try {\n      Contracts.throwIfDisposed(this.privDisposed);\n      const requestId = createNoDashGuid();\n      let audioDestination;\n\n      if (dataStream instanceof PushAudioOutputStreamCallback) {\n        audioDestination = new PushAudioOutputStreamImpl(dataStream);\n      } else if (dataStream instanceof PullAudioOutputStream) {\n        audioDestination = dataStream;\n      } else if (dataStream !== undefined) {\n        audioDestination = new AudioFileWriter(dataStream);\n      } else {\n        audioDestination = undefined;\n      }\n\n      this.synthesisRequestQueue.enqueue(new SynthesisRequest(requestId, text, IsSsml, e => {\n        this.privSynthesizing = false;\n\n        if (!!cb) {\n          try {\n            cb(e);\n          } catch (e) {\n            if (!!err) {\n              err(e);\n            }\n          }\n        }\n\n        cb = undefined;\n        /* eslint-disable no-empty */\n\n        this.adapterSpeak().catch(() => {});\n      }, e => {\n        if (!!err) {\n          err(e);\n        }\n      }, audioDestination));\n      /* eslint-disable no-empty-function */\n\n      this.adapterSpeak().catch(() => {});\n    } catch (error) {\n      if (!!err) {\n        if (error instanceof Error) {\n          const typedError = error;\n          err(typedError.name + \": \" + typedError.message);\n        } else {\n          err(error);\n        }\n      } // Destroy the synthesizer.\n\n      /* eslint-disable no-empty */\n\n\n      this.dispose(true).catch(() => {});\n    }\n  }\n\n  getVoices(locale) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const requestId = createNoDashGuid();\n      const response = yield this.privRestAdapter.getVoicesList(requestId);\n\n      if (response.ok && Array.isArray(response.json)) {\n        let json = response.json;\n\n        if (!!locale && locale.length > 0) {\n          json = json.filter(item => !!item.Locale && item.Locale.toLowerCase() === locale.toLowerCase());\n        }\n\n        return new SynthesisVoicesResult(requestId, json, undefined);\n      } else {\n        return new SynthesisVoicesResult(requestId, undefined, `Error: ${response.status}: ${response.statusText}`);\n      }\n    });\n  }\n\n  adapterSpeak() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privDisposed && !this.privSynthesizing) {\n        this.privSynthesizing = true;\n        const request = yield this.synthesisRequestQueue.dequeue();\n        return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);\n      }\n    });\n  }\n\n  static XMLEncode(text) {\n    return text.replace(/&/g, \"&amp;\").replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\").replace(/\"/g, \"&quot;\").replace(/'/g, \"&apos;\");\n  }\n\n}\nexport class SynthesisRequest {\n  constructor(requestId, text, isSSML, cb, err, dataStream) {\n    this.requestId = requestId;\n    this.text = text;\n    this.isSSML = isSSML;\n    this.cb = cb;\n    this.err = err;\n    this.dataStream = dataStream;\n  }\n\n} //# sourceMappingURL=SpeechSynthesizer.js.map","map":null,"metadata":{},"sourceType":"module"}